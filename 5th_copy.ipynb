{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vLgBzt2I42xT7qJ6QelQOUA7vNQwRQTX",
      "authorship_tag": "ABX9TyP0VjU5RKaUGu3nWVxeu2o6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sakib635/sage2.0/blob/main/5th_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install z3-solver\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG3O-ME98k52",
        "outputId": "623166b2-4b30-4e73-f244-826791a282a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting z3-solver\n",
            "  Downloading z3_solver-4.13.0.0-py2.py3-none-manylinux2014_x86_64.whl (57.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: z3-solver\n",
            "Successfully installed z3-solver-4.13.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ToAOPB_PmhV5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import logging\n",
        "from z3 import Solver, Bool, Or, And, Implies, sat, Int, String, Not, Real, simplify, Optimize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_requirements(requirements_txt):\n",
        "    \"\"\"\n",
        "    Parses the content of requirements.txt into a dictionary of packages and their version specifiers.\n",
        "    Handles cases where version specifiers might include an \"extra\" part after a semicolon, and cases where there are no version specifiers.\n",
        "\n",
        "    Parameters:\n",
        "        requirements_txt (str): The content of the requirements.txt file as a single string.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are package names and values are lists of tuples representing version specifiers.\n",
        "              If a package has no version specifiers, the value will be an empty list.\n",
        "    \"\"\"\n",
        "    requirements = {}  # Initialize an empty dictionary to store package requirements\n",
        "    lines = requirements_txt.strip().split('\\n')  # Split the input string into lines\n",
        "    for line in lines:  # Iterate through each line\n",
        "        line = line.strip()  # Trim whitespace from the line\n",
        "        if line:  # Check if the line is not empty\n",
        "            # Split the line into parts based on version specifiers using a regular expression\n",
        "            parts = re.split(r'([><!=]=?[\\d.*]+(?:, )?)', line)\n",
        "            # Extract the package name from the first part, handling extra parts after a semicolon\n",
        "            package = parts[0].strip().split(';')[0].strip()\n",
        "            version_specs = parts[1:]  # Extract version specifiers from the remaining parts\n",
        "\n",
        "            if not version_specs:  # If there are no version specifiers\n",
        "                requirements[package] = []  # Add the package with an empty list of specifiers\n",
        "            else:\n",
        "                for spec in version_specs:  # Iterate through each version specifier\n",
        "                    if spec.strip():  # Trim whitespace from the specifier\n",
        "                        # Match the specifier with a regular expression to extract the operator and version\n",
        "                        match = re.match(r'([><!=]=?)([\\d.*]+)', spec.strip())\n",
        "                        if match:  # If the match is successful\n",
        "                            operator, version = match.groups()  # Extract the operator and version\n",
        "                            if package in requirements:  # If the package is already in the dictionary\n",
        "                                requirements[package].append((operator, version))  # Append the (operator, version) tuple to the list\n",
        "                            else:\n",
        "                                requirements[package] = [(operator, version)]  # Add the package with a new list containing the (operator, version) tuple\n",
        "    return requirements  # Return the dictionary of requirements\n"
      ],
      "metadata": {
        "id": "J6ssdqvUmnp-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def version_satisfies(version, spec):\n",
        "    \"\"\"\n",
        "    Check if a version satisfies a given version specifier.\n",
        "\n",
        "    Args:\n",
        "    version (str): The version of the package.\n",
        "    spec (tuple): A tuple containing the version operator and version number.\n",
        "\n",
        "    Returns:\n",
        "    bool: True if the version satisfies the specifier, False otherwise.\n",
        "    \"\"\"\n",
        "    operator, spec_version = spec\n",
        "    if operator == '==':\n",
        "        return re.match(spec_version.replace('*', '.*'), version) is not None\n",
        "    elif operator == '!=':\n",
        "        return re.match(spec_version.replace('*', '.*'), version) is None\n",
        "    elif operator == '>':\n",
        "        return version > spec_version\n",
        "    elif operator == '>=':\n",
        "        return version >= spec_version\n",
        "    elif operator == '<':\n",
        "        return version < spec_version\n",
        "    elif operator == '<=':\n",
        "        return version <= spec_version\n",
        "    return False\n",
        "\n",
        "def find_matching_versions(package, specs, projects_data):\n",
        "    \"\"\"\n",
        "    Find all versions of a package that satisfy the given version specifiers.\n",
        "\n",
        "    Args:\n",
        "    package (str): The name of the package.\n",
        "    specs (list): A list of tuples containing version operators and version numbers.\n",
        "    projects_data (dict): A dictionary containing project data with available versions.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of versions that satisfy the given specs.\n",
        "    \"\"\"\n",
        "    if package not in projects_data:\n",
        "        return []\n",
        "\n",
        "    versions = projects_data[package].keys()  # Get all versions of the package.\n",
        "    matching_versions = []\n",
        "    for version in versions:\n",
        "        if all(version_satisfies(version, spec) for spec in specs):\n",
        "            matching_versions.append(version)  # Add version if it satisfies all specs.\n",
        "    return matching_versions\n",
        "\n",
        "def fetch_direct_dependencies(requirements, projects_data):\n",
        "    \"\"\"\n",
        "    Fetch direct dependencies for each package based on the parsed requirements.\n",
        "\n",
        "    Args:\n",
        "    requirements (dict): A dictionary where keys are package names and values are lists of tuples with version specs.\n",
        "    projects_data (dict): A dictionary containing project data with available versions and dependencies.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where keys are package names and values are lists of matching versions.\n",
        "    \"\"\"\n",
        "    direct_dependencies = {}\n",
        "\n",
        "    for package, specs in requirements.items():\n",
        "        matching_versions = find_matching_versions(package, specs, projects_data[\"projects\"])\n",
        "        direct_dependencies[package] = matching_versions  # Store matching versions for the package.\n",
        "\n",
        "    return direct_dependencies\n"
      ],
      "metadata": {
        "id": "rMgRHphTrrYR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_dependency(dependency):\n",
        "    \"\"\"\n",
        "    Parse a dependency string into a package and a list of version specifiers.\n",
        "\n",
        "    Parameters:\n",
        "        dependency (str): A string representing a package and its version specifiers.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple where the first element is the package name and the second element is a list of tuples representing version specifiers.\n",
        "    \"\"\"\n",
        "    # Split the dependency string into parts based on version specifiers using a regular expression\n",
        "    parts = re.split(r'([><!=]=?[\\d.*]+(?:, )?)', dependency)\n",
        "    # Extract the package name from the first part, handling extra parts after a semicolon\n",
        "    package = parts[0].strip().split(';')[0].strip()\n",
        "    version_specs = []  # Initialize an empty list to store version specifiers\n",
        "\n",
        "    # Iterate through the remaining parts\n",
        "    for spec in parts[1:]:\n",
        "        if spec.strip():  # Trim whitespace from the specifier\n",
        "            # Match the specifier with a regular expression to extract the operator and version\n",
        "            match = re.match(r'([><!=]=?)([\\d.*]+)', spec.strip())\n",
        "            if match:  # If the match is successful\n",
        "                operator, version = match.groups()  # Extract the operator and version\n",
        "                version_specs.append((operator, version))  # Append the (operator, version) tuple to version_specs\n",
        "\n",
        "    return package, version_specs  # Return the package and version_specs\n",
        "\n",
        "def fetch_transitive_dependencies(direct_dependencies, projects_data):\n",
        "    \"\"\"\n",
        "    Recursively fetch transitive dependencies for each version of the packages in direct dependencies.\n",
        "\n",
        "    Parameters:\n",
        "        direct_dependencies (dict): A dictionary of direct dependencies where keys are package names and values are lists of versions.\n",
        "        projects_data (dict): A dictionary containing project data, including available versions and their dependencies.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are package versions and values are dictionaries of transitive dependencies.\n",
        "    \"\"\"\n",
        "    transitive_dependencies = {}  # Initialize an empty dictionary to store transitive dependencies\n",
        "\n",
        "    def _fetch(package, version):\n",
        "        key = f\"{package}=={version}\"  # Create a key as \"package==version\"\n",
        "        if key in transitive_dependencies:  # If the key is already in transitive_dependencies, return the stored value\n",
        "            return transitive_dependencies[key]\n",
        "\n",
        "        # Handle case sensitivity for package lookup\n",
        "        version_data = projects_data[\"projects\"].get(package, {}).get(version, {})\n",
        "        if not version_data:  # If version_data is empty, try lowercase version of the package name\n",
        "            version_data = projects_data[\"projects\"].get(package.lower(), {}).get(version, {})\n",
        "\n",
        "        dependencies = {}  # Initialize an empty dictionary to store dependencies\n",
        "        if version_data.get(\"dependency_packages\"):  # If version_data contains dependency_packages\n",
        "            for dep in version_data[\"dependency_packages\"]:\n",
        "                dep_package, dep_specs = parse_dependency(dep)  # Parse dep to get dep_package and dep_specs\n",
        "\n",
        "                # Handle case sensitivity for dependency package lookup\n",
        "                matching_versions = []\n",
        "                if not dep_specs:  # If no version specifiers are provided, fetch all versions of the dependency package\n",
        "                    matching_versions = list(projects_data[\"projects\"].get(dep_package, {}).keys())\n",
        "                    if not matching_versions:  # Try lowercase version of the dependency package name if no versions found\n",
        "                        matching_versions = list(projects_data[\"projects\"].get(dep_package.lower(), {}).keys())\n",
        "                else:  # If there are version specifiers, fetch matching versions of the dependency package\n",
        "                    matching_versions = find_matching_versions(dep_package, dep_specs, projects_data[\"projects\"])\n",
        "\n",
        "                dependencies[dep_package] = matching_versions  # Add dep_package with matching versions to dependencies\n",
        "                for dep_version in matching_versions:  # Recursively fetch dependencies for each matching version\n",
        "                    _fetch(dep_package, dep_version)\n",
        "\n",
        "        # Ensure that an empty dictionary is assigned if no dependencies are found\n",
        "        transitive_dependencies[key] = dependencies\n",
        "        return dependencies  # Return the dependencies for this package and version\n",
        "\n",
        "    for package, versions in direct_dependencies.items():  # Iterate through direct dependencies\n",
        "        for version in versions:  # Iterate through each version of the package\n",
        "            _fetch(package, version)  # Fetch transitive dependencies for the package and version\n",
        "\n",
        "    return transitive_dependencies  # Return the transitive dependencies dictionary\n"
      ],
      "metadata": {
        "id": "USg4Guyox1Tb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_smt_expression(direct_dependencies, transitive_dependencies):\n",
        "    \"\"\"\n",
        "    Generate an SMT (Satisfiability Modulo Theories) expression to handle package version constraints,\n",
        "    including both direct and transitive dependencies, using an Optimize solver.\n",
        "\n",
        "    Args:\n",
        "    direct_dependencies (dict): A dictionary where keys are package names and values are lists of matching versions.\n",
        "    transitive_dependencies (dict): A dictionary where keys are \"package==version\" and values are dictionaries of transitive dependencies.\n",
        "\n",
        "    Returns:\n",
        "    tuple: An Optimize solver instance with the added constraints and the list of constraints.\n",
        "    \"\"\"\n",
        "    # Initialize an Optimize solver to handle both hard and soft constraints\n",
        "    solver = Optimize()\n",
        "    constraints = []\n",
        "\n",
        "    # Generate constraints for direct dependencies\n",
        "    for package, versions in direct_dependencies.items():\n",
        "        if isinstance(versions, list):\n",
        "            # Create a constraint that the package version must be one of the specified versions\n",
        "            package_constraint = Or([String(package) == v for v in versions])\n",
        "            constraints.append(package_constraint)\n",
        "            # Add soft constraints with weights for versions\n",
        "            sorted_versions = sorted(versions, reverse=False)  # Sort versions to prioritize newer versions\n",
        "            weight = 1\n",
        "            for version in sorted_versions:\n",
        "                # Add a soft constraint with increasing weight for newer versions\n",
        "                solver.add_soft(String(package) == version, weight)\n",
        "                weight += 1  # Increment the weight for the next version\n",
        "\n",
        "    # Generate constraints for transitive dependencies\n",
        "    for package_version, dependencies in transitive_dependencies.items():\n",
        "        if isinstance(dependencies, dict):\n",
        "            # Split the package_version to get the package name and its version\n",
        "            package, version = package_version.split('==')\n",
        "            for dep_package, dep_versions in dependencies.items():\n",
        "                # Create a constraint for each dependency that it must be one of the specified versions\n",
        "                dependency_constraint = Or([String(dep_package) == dep_version for dep_version in dep_versions])\n",
        "                constraints.append(Implies(String(package) == version, dependency_constraint))\n",
        "                # Add soft constraints with weights for versions\n",
        "                sorted_versions = sorted(dep_versions, reverse=False)  # Sort versions to prioritize newer versions\n",
        "                weight = 1\n",
        "                for dep_version in sorted_versions:\n",
        "                    # Add a soft constraint with increasing weight for newer versions\n",
        "                    solver.add_soft(String(dep_package) == dep_version, weight)\n",
        "                    weight += 1  # Increment the weight for the next version\n",
        "\n",
        "    # Combine all constraints into a single final constraint\n",
        "    final_constraint = And(constraints)\n",
        "    solver.add(final_constraint)\n",
        "\n",
        "    return solver, constraints\n"
      ],
      "metadata": {
        "id": "pztQhfhV8CUK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def smt_solver(solver):\n",
        "    \"\"\"\n",
        "    Solve the SMT (Satisfiability Modulo Theories) expression using the provided solver.\n",
        "\n",
        "    Args:\n",
        "    solver (Optimize): An Optimize solver instance with added constraints.\n",
        "\n",
        "    Returns:\n",
        "    dict or None: A dictionary representing the solution model if satisfiable, otherwise None.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    # Check for the maximum satisfaction\n",
        "    if solver.check() == sat:\n",
        "        # Get the model\n",
        "        model = solver.model()\n",
        "        elapsed_time = time.time() # Calculate elapsed time before returning\n",
        "        # Return the solution model as a dictionary\n",
        "        return {d.name(): model[d] for d in model.decls()}, start_time, elapsed_time\n",
        "    else:\n",
        "        # Print a message if the constraints are not satisfiable\n",
        "        print(\"Not satisfiable.\")\n",
        "        return None, None, None # Return None for all values if no solution"
      ],
      "metadata": {
        "id": "a54sv5uM9Jiq"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_requirements(directory):\n",
        "    \"\"\"\n",
        "    Reads the content of the `requirements.txt` file from a specified directory.\n",
        "\n",
        "    Parameters:\n",
        "        directory (str): The path to the directory containing the `requirements.txt` file.\n",
        "\n",
        "    Returns:\n",
        "        str: The content of the `requirements.txt` file as a single string.\n",
        "    \"\"\"\n",
        "    with open(os.path.join(directory, 'r30.txt'), 'r') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Function to read the JSON file from a directory\n",
        "def read_json_file(directory, filename='updated_formated_8k.json'):\n",
        "    \"\"\"\n",
        "    Reads the content of a JSON file from a specified directory.\n",
        "\n",
        "    Parameters:\n",
        "        directory (str): The path to the directory containing the JSON file.\n",
        "        filename (str): The name of the JSON file to read. Default is 'updated_formated_8k.json'.\n",
        "\n",
        "    Returns:\n",
        "        dict: The content of the JSON file as a dictionary.\n",
        "    \"\"\"\n",
        "    with open(os.path.join(directory, filename), 'r') as file:\n",
        "        return json.load(file)"
      ],
      "metadata": {
        "id": "fpQXmzU3mvxM"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to execute the dependency resolution process, including reading files,\n",
        "    parsing requirements, fetching dependencies, generating SMT expressions, and solving them.\n",
        "    \"\"\"\n",
        "    directory = '/content/drive/MyDrive/smart pip sample data'\n",
        "\n",
        "    # Log file setup\n",
        "    log_file = 'execution_log.txt'\n",
        "\n",
        "    def log_execution_time(action_name, start_time, end_time):\n",
        "        \"\"\"\n",
        "        Log the execution time of a specific action to a log file.\n",
        "\n",
        "        Args:\n",
        "        action_name (str): The name of the action being logged.\n",
        "        start_time (float): The start time of the action.\n",
        "        end_time (float): The end time of the action.\n",
        "        \"\"\"\n",
        "        with open(log_file, 'a') as file:\n",
        "            file.write(f'{action_name} execution time: {end_time - start_time} seconds\\n')\n",
        "\n",
        "    # Read files from the directory\n",
        "    start_time = time.time()\n",
        "    requirements_txt = read_requirements(directory)\n",
        "    projects_data = read_json_file(directory)\n",
        "    end_time = time.time()\n",
        "    log_execution_time(\"Reading files\", start_time, end_time)\n",
        "\n",
        "    # Parse requirements\n",
        "    start_time = time.time()\n",
        "    requirements = parse_requirements(requirements_txt)\n",
        "    # assert parse_requirements(\"python-sat>=3.1\") == (\"python-sat\", [(\">=\", 3.1)])\n",
        "    end_time = time.time()\n",
        "    log_execution_time(\"Parsing requirements\", start_time, end_time)\n",
        "    print(\"Parsed requirements:\", requirements)\n",
        "\n",
        "    # Fetch matching versions and their dependencies\n",
        "    start_time = time.time()\n",
        "    direct_dependencies = fetch_direct_dependencies(requirements, projects_data)\n",
        "    end_time = time.time()\n",
        "    log_execution_time(\"Fetching versions and dependencies\", start_time, end_time)\n",
        "    print(\"Direct dependencies:\", direct_dependencies)\n",
        "\n",
        "    # Fetch transitive dependencies\n",
        "    start_time = time.time()\n",
        "    transitive_dependencies = fetch_transitive_dependencies(direct_dependencies, projects_data)\n",
        "    end_time = time.time()\n",
        "    log_execution_time(\"Fetching transitive dependencies\", start_time, end_time)\n",
        "    print(\"Transitive dependencies:\", transitive_dependencies)\n",
        "\n",
        "    # Generate SMT expression\n",
        "    start_time = time.time()\n",
        "    solver, constraints = generate_smt_expression(direct_dependencies, transitive_dependencies)\n",
        "    end_time = time.time()\n",
        "    log_execution_time(\"Generating SMT expression\", start_time, end_time)\n",
        "\n",
        "    # Save SMT expression to a file (optional)\n",
        "    with open('SMT_expression.txt', 'w') as file:\n",
        "        file.write(str(solver))\n",
        "\n",
        "    # Solve the SMT expression\n",
        "\n",
        "    solution, start_time, end_time = smt_solver(solver)\n",
        "\n",
        "    if solution: # Check if a solution was found before logging and printing\n",
        "        log_execution_time(\"Solving SMT expression\", start_time, end_time)\n",
        "        print(f'Optimal Solution: {solution}')\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3vnRi599eFj",
        "outputId": "c7183130-4125-410e-8e82-0443e9979574"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed requirements: {'Django': [('==', '3.1.7')], 'utils': [('==', '1.0.1')]}\n",
            "Direct dependencies: {'Django': ['3.1.7'], 'utils': ['1.0.1']}\n",
            "Transitive dependencies: {'asgiref==3.8.1': {}, 'asgiref==3.8.0': {}, 'asgiref==3.7.2': {}, 'asgiref==3.7.1': {}, 'asgiref==3.7.0': {}, 'asgiref==3.6.0': {}, 'asgiref==3.5.2': {}, 'asgiref==3.5.1': {}, 'asgiref==3.5.0': {}, 'asgiref==3.4.1': {}, 'asgiref==3.4.0': {}, 'asgiref==3.3.4': {}, 'asgiref==3.3.3': {}, 'asgiref==3.3.2': {}, 'asgiref==3.3.1': {}, 'asgiref==3.3.0': {}, 'asgiref==3.2.10': {}, 'asgiref==3.2.9': {}, 'asgiref==3.2.8': {}, 'asgiref==3.2.7': {}, 'asgiref==3.2.6': {}, 'asgiref==3.2.5': {}, 'asgiref==3.2.4': {}, 'asgiref==3.2.3': {}, 'asgiref==3.2.2': {}, 'pytz==2004a': {}, 'pytz==2004b': {}, 'pytz==2004b.2': {}, 'pytz==2004d': {}, 'pytz==2005a': {}, 'pytz==2005e': {}, 'pytz==2005i': {}, 'pytz==2005k': {}, 'pytz==2005m': {}, 'pytz==2005r': {}, 'pytz==2006g': {}, 'pytz==2006j': {}, 'pytz==2006p': {}, 'pytz==2007c': {}, 'pytz==2007d': {}, 'pytz==2007f': {}, 'pytz==2007g': {}, 'pytz==2007i': {}, 'pytz==2007k': {}, 'pytz==2008a': {}, 'pytz==2008b': {}, 'pytz==2008c': {}, 'pytz==2008g': {}, 'pytz==2008h': {}, 'pytz==2008i': {}, 'pytz==2009a': {}, 'pytz==2009d': {}, 'pytz==2009e': {}, 'pytz==2009f': {}, 'pytz==2009g': {}, 'pytz==2009i': {}, 'pytz==2009j': {}, 'pytz==2009l': {}, 'pytz==2009n': {}, 'pytz==2009p': {}, 'pytz==2009r': {}, 'pytz==2009u': {}, 'pytz==2010b': {}, 'pytz==2010e': {}, 'pytz==2010g': {}, 'pytz==2010h': {}, 'pytz==2010k': {}, 'pytz==2010l': {}, 'pytz==2010o': {}, 'pytz==2011b': {}, 'pytz==2011c': {}, 'pytz==2011d': {}, 'pytz==2011e': {}, 'pytz==2011g': {}, 'pytz==2011h': {}, 'pytz==2011j': {}, 'pytz==2011k': {}, 'pytz==2011n': {}, 'pytz==2012b': {}, 'pytz==2012c': {}, 'pytz==2012d': {}, 'pytz==2012f': {}, 'pytz==2012g': {}, 'pytz==2012h': {}, 'pytz==2012j': {}, 'pytz==2013.6': {}, 'pytz==2013.7': {}, 'pytz==2013.8': {}, 'pytz==2013.9': {}, 'pytz==2013b': {}, 'pytz==2013d': {}, 'pytz==2014.1': {}, 'pytz==2014.1.1': {}, 'pytz==2014.10': {}, 'pytz==2014.2': {}, 'pytz==2014.3': {}, 'pytz==2014.4': {}, 'pytz==2014.7': {}, 'pytz==2014.9': {}, 'pytz==2015.2': {}, 'pytz==2015.4': {}, 'pytz==2015.6': {}, 'pytz==2015.7': {}, 'pytz==2016.1': {}, 'pytz==2016.10': {}, 'pytz==2016.2': {}, 'pytz==2016.3': {}, 'pytz==2016.4': {}, 'pytz==2016.6': {}, 'pytz==2016.6.1': {}, 'pytz==2016.7': {}, 'pytz==2017.2': {}, 'pytz==2017.3': {}, 'pytz==2018.3': {}, 'pytz==2018.4': {}, 'pytz==2018.5': {}, 'pytz==2018.6': {}, 'pytz==2018.7': {}, 'pytz==2018.9': {}, 'pytz==2019.1': {}, 'pytz==2019.2': {}, 'pytz==2019.3': {}, 'pytz==2020.1': {}, 'pytz==2020.4': {}, 'pytz==2020.5': {}, 'pytz==2021.1': {}, 'pytz==2021.3': {}, 'pytz==2022.1': {}, 'pytz==2022.2': {}, 'pytz==2022.2.1': {}, 'pytz==2022.4': {}, 'pytz==2022.5': {}, 'pytz==2022.6': {}, 'pytz==2022.7': {}, 'pytz==2022.7.1': {}, 'pytz==2023.2': {}, 'pytz==2023.3': {}, 'pytz==2023.3.post1': {}, 'pytz==2023.4': {}, 'pytz==2024.1': {}, 'sqlparse==0.5.0': {}, 'sqlparse==0.4.4': {}, 'sqlparse==0.4.3': {}, 'sqlparse==0.4.2': {}, 'sqlparse==0.4.1': {}, 'sqlparse==0.4.0': {}, 'sqlparse==0.3.1': {}, 'sqlparse==0.3.0': {}, 'sqlparse==0.2.4': {}, 'sqlparse==0.2.3': {}, 'sqlparse==0.2.2': {}, 'Django==3.1.7': {'asgiref': ['3.8.1', '3.8.0', '3.7.2', '3.7.1', '3.7.0', '3.6.0', '3.5.2', '3.5.1', '3.5.0', '3.4.1', '3.4.0', '3.3.4', '3.3.3', '3.3.2', '3.3.1', '3.3.0', '3.2.10', '3.2.9', '3.2.8', '3.2.7', '3.2.6', '3.2.5', '3.2.4', '3.2.3', '3.2.2'], 'pytz': ['2004a', '2004b', '2004b.2', '2004d', '2005a', '2005e', '2005i', '2005k', '2005m', '2005r', '2006g', '2006j', '2006p', '2007c', '2007d', '2007f', '2007g', '2007i', '2007k', '2008a', '2008b', '2008c', '2008g', '2008h', '2008i', '2009a', '2009d', '2009e', '2009f', '2009g', '2009i', '2009j', '2009l', '2009n', '2009p', '2009r', '2009u', '2010b', '2010e', '2010g', '2010h', '2010k', '2010l', '2010o', '2011b', '2011c', '2011d', '2011e', '2011g', '2011h', '2011j', '2011k', '2011n', '2012b', '2012c', '2012d', '2012f', '2012g', '2012h', '2012j', '2013.6', '2013.7', '2013.8', '2013.9', '2013b', '2013d', '2014.1', '2014.1.1', '2014.10', '2014.2', '2014.3', '2014.4', '2014.7', '2014.9', '2015.2', '2015.4', '2015.6', '2015.7', '2016.1', '2016.10', '2016.2', '2016.3', '2016.4', '2016.6', '2016.6.1', '2016.7', '2017.2', '2017.3', '2018.3', '2018.4', '2018.5', '2018.6', '2018.7', '2018.9', '2019.1', '2019.2', '2019.3', '2020.1', '2020.4', '2020.5', '2021.1', '2021.3', '2022.1', '2022.2', '2022.2.1', '2022.4', '2022.5', '2022.6', '2022.7', '2022.7.1', '2023.2', '2023.3', '2023.3.post1', '2023.4', '2024.1'], 'sqlparse': ['0.5.0', '0.4.4', '0.4.3', '0.4.2', '0.4.1', '0.4.0', '0.3.1', '0.3.0', '0.2.4', '0.2.3', '0.2.2']}, 'utils==1.0.1': {}}\n",
            "Optimal Solution: {'pytz': \"2024.1\", 'asgiref': \"3.8.1\", 'sqlparse': \"0.5.0\", 'Django': \"3.1.7\", 'utils': \"1.0.1\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0GRIgatqQXXl"
      },
      "execution_count": 204,
      "outputs": []
    }
  ]
}